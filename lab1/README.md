# Список файлов и их краткое описание

* docker-compose.yaml - docker compose файл, содержащий все необходимые сервисы для работы (kakfa+zookeeper+kafka-ui)
* create-topic.sh - bash скрипт для создания топика, а так же вывода информации о созданном топике
* message.py - содержит класс сообщения Message, который отправляем/получаем
* custom_serializer.py - содержит классы для сериаллизации и десериаллизации сообщения Message
* producer.py - мини приложение-продюсер, отправляет сообщения класса Message в кафку
* consumer_pull.py - кансамер забирает сообщения из топика с эмуляцией переодического pull 
* consumer_push.py - кансамер забирает сообщения из топика с эмуляцией push
* consumed_messages.txt - эмуляция некого S3 Sink, то есть файл полученных сообщений.

# Описание

Для работы необходимо поднять docker compose:
```shell
docker compose up -d
```

Для создания необходимых тописов
```shell
./create-topic.sh
```

Для начала отправки сообщений необходимо запустить producer.py
```shell
python producer.py
```

Необходимо запустить 2 кансамера, намеприме из консоли
```shell
python consumer_pull.py
```
```shell
python consumer_push.py
```

# Краткие замечания

* Тут используется 2 разных кансамера, чтобы было создано 2 разных "потока", если один упадет второй продолжит работать.
Считаем что это 2 разных и независимых pod в k8s. :-)
* Так жа каждый из кансамеров использует разные group.id для того чтобы могли читать одни и те же сообщения, т.к. кафка отсдеживает оффесты для группы, а не каждого кансамера.